AI_resnet50_inference_throughput_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_throughput_amx_int8
AI_resnet50_inference_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_throughput_amx_bfloat16
AI_resnet50_inference_throughput_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_throughput_vnni_int8
AI_resnet50_inference_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_throughput_fp32
AI_resnet50_inference_latency_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_latency_amx_int8
AI_resnet50_inference_latency_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_latency_amx_bfloat16
AI_resnet50_inference_latency_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_latency_vnni_int8
AI_resnet50_inference_latency_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet50_inference_latency_fp32
AI_ssd_mobilenet_inference_throughput_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_throughput_amx_int8
AI_ssd_mobilenet_inference_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_throughput_amx_bfloat16
AI_ssd_mobilenet_inference_throughput_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_throughput_vnni_int8
AI_ssd_mobilenet_inference_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_throughput_fp32
AI_ssd_mobilenet_inference_latency_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_latency_amx_int8
AI_ssd_mobilenet_inference_latency_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_latency_amx_bfloat16
AI_ssd_mobilenet_inference_latency_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase  ssd_mobilenet_inference_latency_vnni_int8
AI_ssd_mobilenet_inference_latency_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_mobilenet_inference_latency_fp32
AI_ssd_resnet34_inference_throughput_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_throughput_amx_int8
AI_ssd_resnet34_inference_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_throughput_amx_bfloat16
AI_ssd_resnet34_inference_throughput_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_throughput_vnni_int8
AI_ssd_resnet34_inference_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_throughput_fp32
AI_ssd_resnet34_inference_latency_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_latency_amx_int8
AI_ssd_resnet34_inference_latency_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_latency_amx_bfloat16
AI_ssd_resnet34_inference_latency_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_latency_vnni_int8
AI_ssd_resnet34_inference_latency_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase ssd_resnet34_inference_latency_fp32
AI_mobilenet_v1_inference_throughput_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_throughput_amx_int8
AI_mobilenet_v1_inference_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_throughput_amx_bfloat16
AI_mobilenet_v1_inference_throughput_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_throughput_vnni_int8
AI_mobilenet_v1_inference_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_throughput_fp32
AI_mobilenet_v1_inference_latency_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_latency_amx_int8
AI_mobilenet_v1_inference_latency_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_latency_amx_bfloat16
AI_mobilenet_v1_inference_latency_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_latency_vnni_int8
AI_mobilenet_v1_inference_latency_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase mobilenet_v1_inference_latency_fp32
AI_bert_large_squad_inference_throughput_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_throughput_amx_int8
AI_bert_large_squad_inference_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_throughput_amx_bfloat16
AI_bert_large_squad_inference_throughput_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_throughput_vnni_int8
AI_bert_large_squad_inference_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_throughput_fp32
AI_bert_large_squad_inference_latency_amx_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_latency_amx_int8
AI_bert_large_squad_inference_latency_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_latency_amx_bfloat16
AI_bert_large_squad_inference_latency_vnni_int8,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_latency_vnni_int8
AI_bert_large_squad_inference_latency_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase bert_large_squad_inference_latency_fp32
AI_resnet_50_training_throughput_amx_bfloat16,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet_50_training_throughput_amx_bfloat16
AI_resnet_50_training_throughput_fp32,src/pnp/tests/run_pnp_test.py --workload ai --testcase resnet_50_training_throughput_fp32
